{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Analysis Process Book</center></h1>\n",
    "\n",
    "This notebook contains an general view of the process adopted in this project. The overall project was\n",
    "devided in several other notebooks with the aim of making it easier to understand, since putting it all in\n",
    "one file would make the document too large and convoluted. In this notebook we direct each task to the\n",
    "notebook containing the respective code.\n",
    "\n",
    "\n",
    "## OVERVIEW:\n",
    "The Curriculum Lattes is a cv of the academic activities of students and researchers of Brazil. Stored at Plataforma Lattes, this cv format is adopted by most academic institutions and research centres of Brazil, therefore, constituting a rich source of information to study the academic production of the country.\n",
    "At Platform Lattes, the researchers inform their area of study, making it possible to analyse the data by research area.\n",
    "In this project, we analyse the data for the researchers in mathematics. We also obtained and analysed the researchers with areas listed as computer science, probability and statistics, since we consider them to be part of mathematics as a whole.\n",
    "\n",
    "## OBJECTIVES:\n",
    "Our aim is to get an overall understanding of how is the research network of mathematics of the researches in Plataforma Lattes. For that we:\n",
    "* Extract some fundamental statistics regarding the research in mathematics, such as total number of researchers, total number of publications, average number of publication per researcher.\n",
    "* Generate a co-authorship network and study the properties of such network, as the number of edges, degree distribution, number of connected components, average shortest path.\n",
    "\n",
    "## MOTIVATION:\n",
    "We are Brazilian math students, do we need to say more?! Learning about the mathematics research network, questions such who are the researchers that publish the most, how is research evolving over time, do mathematicians in the network collaborate among themselves, what is their degrees of separation...\n",
    "\n",
    "## REPOSITORY:\n",
    "\n",
    "### 1) [Example_Data_Scraping](Example_Data_Scraping.ipynb)\n",
    "This is an example of the method we used to extract the cvs from Plataforma Lattes. The whole extraction takes more\n",
    "than a day.\n",
    "\n",
    "### 2) [Create_DB_in_Mongo](Create_DB_in_Mongo.ipynb)\n",
    "The name is self-explanatory, this notebook \n",
    "contains the code used to extract each .xml raw file, convert it to json and then insert in a Mongo database, which\n",
    "was then used to query information and create dataframes.\n",
    "\n",
    "### 3) [Dataframe_from_Mongo](Dataframe_from_Mongo.ipynb)\n",
    "This notebook contains the code for doing the queries in MongoDB and create the Dataframes used in the other\n",
    "notebooks. The two dataframes used were Authors.csv and Papers.csv.\n",
    "### 4) [Exploring_Database](Exploring_Database.ipynb)\n",
    "Here is where the exploratory analysis of both Authors and Papers dataframes were explored. From this analysis,\n",
    "several of our motivating questions were answered.\n",
    "### 5) [Create_Network](Create_Network.ipynb )\n",
    "In this notebook the co-authorship network is created and explored. First the network as a whole is studied,\n",
    "then, after learning about the existence of a giant connected component, this giant component is explored\n",
    "by it self. The two main libraries used are networkx and graph-tool, with the last one being used mainly\n",
    "to generate the visualizations due to it having a much better performance than networkx.\n",
    "\n",
    "## ABOUT THE DATA:\n",
    "Plataforma Lattes is a public platform owned by the Brazilian government and is freely available to anyone who has the patience to go through the CAPTCHA and collect it. The raw cv's were in .xml format and were turned into json through python, thus feeding a MongoDB database. Using MonogoDB, we created two main dataframes, one with information regarding the researchers and another one related to the published papers.\n",
    "\n",
    "The cv's collected were the ones marked by the platform as relating researchers from mathematics, computer science and probability & statistics. The total number of documents collected were 11.424, but some of them did not exist anymore by the time we collected them (or were missing for some reason).\n",
    "![alt text](viz/MongoDB_Documents.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
